## Training

Please refer to [this repo](https://github.com/RLHFlow/Online-DPO-R1/tree/main) for the iterative DPO training.
